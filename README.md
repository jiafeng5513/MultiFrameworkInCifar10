Multi framework test in Cifar-10
=====

1. 使用Cifar-10数据测试多种深度学习框架<br>
2. 额外包GraphViz pydot

#### 环境说明
1. Windows 10,Anaconda3,python3.6.1,Keras,PyTorch,Tensorflow,CNTK
2. 使用CNTK时如果提示找不到DLL,请尝试删除java环境变量.

#### 实验说明
1. 五项实验使用的数据标准化方法不完全一致.<br>
2. 由于CNTK-python,CNTK-C#的接口并不完全一致,有些功能的实现,例如学习率策略,优化器等是不相同的.<br>
3. Tensorflow实验中,采用的是1.13版本,在这个版本中已经内置了Keras的API,但是实验并未混合使用tensorflow和Keras的函数,尽管其中的很多函数是兼容的.<br>
4. 和3类似,我们在Keras的实验中使用的并不是tf内置的keras API,而是单独安装了Keras并使用了tensorflow作为后端.
5. batch_normalization在各个框架中的实现不完全相同,为了证明batch_normalization对于该网络的性能影响,我们使用tensorflow实现了一个不带batch_normalization的实验.<br>
6. 由于神经网络的初始化和训练过程存在随机性,无法保证每次训练都能得到相同的结果,但正如我们的五次实验表现的那样,这些随机因素并不会带来特别大的性能波动.<br>
7. 同一个框架上的五次实验是在一台机器上连续五次进行的,而不同的框架上的实验是不同时间进行的.这导致进行不同框架上的实验时,机器硬件状态(例如温度)和软件状态(例如系统更新等后台程序)不完全相同.这会对不同框架的训练时间造成影响,因此本实验提供的训练时间具有有限的参考价值.<br>


#### 结果
##### 1.时间和准确率
使用一块GTX1080,8GB内存,i7-6700K.网络结构如图.

| | | CNTK-python |CNTK-CSharp| Tensorflow |PyTorch |Keras(Tensorflow)|
|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
|1|时间(s) | 2487.314524|2225.2665498| |6721.648751 |6700.541636 |
| |准确率  | 0.8996|0.8562| |0.9208 |0.8173|
|2|时间(s)| 2435.918163|2245.9057546| | 6853.948150|6703.008284|
| |准确率 | 0.8982|0.8419| |0.9195 |0.8234 |
|3|时间(s)| 2432.328233|2296.0720476| |6621.626443 | 6656.811913|
| |准确率 | 0.9006|0.8381| | 0.9204| 0.8471|
|4|时间(s)| 2444.089096|2246.8836310| | 6716.446840| 6461.971883|
| |准确率 | 0.8973|0.8562| |0.9195 | 0.8243|
|5|时间(s)| 2390.495292|2263.8531833| |6845.881102 | 6430.919157|
| |准确率 | 0.8979|0.8410| | 0.9199| 0.8288|
|平|时间(s)|2438.029062 | | | | |
|均|准确率 | 0.8987| | | | |

##### 2.在Tensorflow上实现了去掉batch_normalization的版本,五次实验的结果如下

#### 结果分析
1. CNTK-CSharp的速度最快.但是准确率最差.
2. PyTorch和Keras的速度最慢.
3. Keras的代码量最低,这主要归功于Keras内置了Cifar-10数据集的读取,并且其网络的构建非常简单.
4. 速度:
5. 准确率:
6. 我们看到相同的网络在不同的框架上具备不同的性能.我们认为除了随机因素的影响之外,不同框架对于相同操作的实现有所不同是主要原因.<br>
